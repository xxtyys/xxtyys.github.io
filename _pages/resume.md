---
title: ""
permalink: /resume/
author_profile: true
toc: true
date: 2024-06-30
---


# Resume
> Click [here](/assets/files/chen-yujun-web-resume-en.pdf) to download the PDF version of my **English** resume.
>
<!-- > Click [here](/assets/files/chen-yujun-web-resume-jp.pdf) to download the PDF version of my **Japanese** resume. -->

## Work Experience
- **Data Scientist**  <br>Panasonic R&D, Osaka, Japan (Apr 2024 - Jul 2024)  
    - Collaborated to develop a system analyzing sleep data, enhancing insights into nighttime awakenings and related physiological/environmental factors.
    - Contributed to the validation of system workflows on Node-RED, ensuring efficient system performance.
- **Full-stack Developer and AI Engineer** <br>Looking Up Co., Ltd., Tokyo, Japan (May 2023 – Mar 2024)  
    - Collaborated with a team to develop a web application using Node.js, TypeScript, and MongoDB, which analyzed questionnaire feedback to enhance customer business strategy formulation.
    - Enhanced a text classification model using NLTK, scikit-learn, and pre-trained SpaCy word embeddings to process complex Japanese survey data, achieving 97.02% accuracy and boosting training efficiency.
- **Data Engineer (Internship)** <br>Looking Up Co., Ltd., Tokyo, Japan (Aug 2022 – Mar 2023)  
    - Developed a ML model using NLTK, scikit-learn, and SpaCy to filter and analyze Japanese survey data, serving as the foundation model for product development.
    - Developed APIs for ML models with FastAPI and Flask, creating user manuals for team access.

## Selected Projects
- **LLaVAC: Fine-tuning LLaVA as a Multimodal Sentiment Classifier** (Jan 2024)
    - Proposed a method to fine-tune Large Language-and-Vision Assistant (LLaVA) as a classifier for classifying multimodal sentiment labels by designing a prompt to consider unimodal and multimodal labels and generating predicted labels.
    - Outperformed state-of-the-art baselines by up to 7.31% in accuracy and by 8.76% in weighted-F1 in the MVSA-Single dataset.
- **Multimodal Sentiment Analysis Using Multiple Labels from Different Modalities** (Mar 2023)
    - Collaborated with students to design and implement a sentiment analysis model for social network data, leveraging text, image, and multimodal labels using CLIP, BERT, and RoBERTa. Yielded up to 2% improvement in F1-score over recent models.
    - Attained F1-scores of 74.1% for MVSA-single and 62.0% MVSA-multiple datasets.

## Education
- **Master of Engineering**, Tokyo Institute of Technology, Japan (Apr 2021 - Mar 2023)
    - Major: Information and Communications Engineering
    - Advisor: Prof. [Manabu Okumura](http://www.lr.pi.titech.ac.jp/~oku/index-e.html)
    - Thesis: Multimodal Sentiment Analysis Using Multiple Labels from Different Modalities
- **Bachelor of Business Administration**, South China Agricultural University, Guangzhou, China (Sep 2011 - Jun 2015)
    - Major: Management Information System

## Skills
- **Technical Skills**
    - **Programming Languages**: Python, C, Java, JavaScript, HTML/CSS, TypeScript
    - **ML Toolkits**: PyTorch, Hugging Face, OpenCV, Scikit-learn, Spacy, NLTK
    - **Tools & Technology**: Linux Server, SQL, NoSQL (MongoDB), Docker, Jupyter, GCP, Node-RED

- **Languages**
    - **Chinese**: Native
    - **English**: Advanced, TOEIC: 830/990
    - **Japanese**: Advanced, JLPT-N1

- **Certification**
    - IBM Full Stack Software Developer Professional Certificate (Coursera)